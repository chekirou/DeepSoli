Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{Goodfellow-et-al-2016,
annote = {$\backslash$url{\{}http://www.deeplearningbook.org{\}}},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
publisher = {MIT Press},
title = {{Deep Learning}},
year = {2016}
}
@article{Zhang2018,
abstract = {Recently, hand gesture recognition systems have become increasingly interesting to researchers in the field of human-computer interfaces. Real-world systems for human dynamic hand gesture recognition is challenging as: 1) the system must be robust to various conditions; 2) there is a rich diversity in how people perform hand gestures, making hand gesture recognition difficult; and 3) the system must detect and recognize hand gestures continuously using unsegmented input streams in order to avoid noticeable lag between performing a gesture and its classification. In this paper, to address these challenges, we present Latern, a novel system for dynamic continuous hand gesture recognition based on a frequency-modulated continuous wave radar sensor. The radar system does not depend on lighting, noise, or atmospheric conditions. We employ a recurrent 3-D convolutional neural network to perform the classification of dynamic hand gestures. To enhance the processing performance, a connectionist temporal classification algorithm is used to train the network to predict class labels from inprogress gestures in unsegmented input streams. The experimental results show that Latern is able to achieve high recognition rates of 96{\%}, which is higher than state-of-the-art hand gesture recognition systems. In addition, the conclusion in this paper can be used for a real-time hand gesture recognition system design.},
author = {Zhang, Zhenyuan and Tian, Zengshan and Zhou, Mu},
doi = {10.1109/JSEN.2018.2808688},
issn = {1530437X},
journal = {IEEE Sensors Journal},
keywords = {FMCW radar,Hand gesture recognition,connectionist temporal classification,recurrent three-dimensional convolutional neural n},
month = {apr},
number = {8},
pages = {3278--3289},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Latern: Dynamic Continuous Hand Gesture Recognition Using FMCW Radar Sensor}},
volume = {18},
year = {2018}
}
@inproceedings{Zhao2014,
abstract = {Current smartphone inputs are limited to physical buttons, touchscreens, cameras or built-in sensors. These approaches either require a dedicated surface or line-of-sight for interaction. We introduce SideSwipe, a novel system that enables in-air gestures both above and around a mobile device. Our system leverages the actual (unmodified) GSM signal to detect hand gestures around the device. We developed an algorithm to convert the bursty reflected GSM pulses to a continuous signal that can be used for gesture recognition. Specifically, when a user waves their hand near the phone, the hand movement disturbs the signal propagation between the phone's transmitter and added receiving antennas. Our system captures this variation and uses it for gesture recognition. To evaluate our system, we conduct a study with 10 participants and present robust gesture recognition with an average accuracy of 87.2{\%} across 14 hand gestures.},
address = {New York, New York, USA},
author = {Zhao, Chen and Chen, Ke Yu and Aumi, Md Tanvir Islam and Patel, Shwetak and Reynolds, Matthew S.},
booktitle = {UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/2642918.2647380},
file = {::},
isbn = {9781450330695},
keywords = {Antenna,GSM,In-air hand gesture},
month = {oct},
pages = {527--534},
publisher = {Association for Computing Machinery, Inc},
title = {{SideSwipe: Detecting in-air gestures around mobile devices using actual GSM signals}},
url = {http://dl.acm.org/citation.cfm?doid=2642918.2647380},
year = {2014}
}
@inproceedings{Zhang2017a,
abstract = {Dynamic hand gesture recognition is of great importance for human-computer interaction. In this paper, we present a method to discriminate the four kinds of dynamic hand gestures, snapping fingers, flipping fingers, hand rotation and calling, using a radar micro-Doppler sensor. Two micro-Doppler features are extracted from the time-frequency spectrum and the support vector machine is used to classify these four kinds of gestures. The experimental results on measured data demonstrate that the proposed method can produce a classification accuracy higher than 88.56{\%}.},
author = {Zhang, Shimeng and Li, Gang and Ritchie, Matthew and Fioranelli, Francesco and Griffiths, Hugh},
booktitle = {2016 CIE International Conference on Radar, RADAR 2016},
doi = {10.1109/RADAR.2016.8059518},
isbn = {9781509048281},
keywords = {Hand gesture classification,Human-computer interaction,Micro-Doppler signatures,Support vector machine},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic hand gesture classification based on radar micro-Doppler signatures}},
year = {2017}
}
@article{Kim2016,
abstract = {In this paper, we investigate the feasibility of recognizing human hand gestures using micro-Doppler signatures measured by Doppler radar with a deep convolutional neural network (DCNN). Hand gesture recognition using radar can be applied to control electronic appliances. Compared with an optical recognition system, radar can work regardless of light conditions and it can be embedded in a case. We classify ten different hand gestures, with only micro-Doppler signatures on spectrograms without range information. The ten gestures, which included swiping from left to right, swiping from right to left, rotating clockwise, rotating counterclockwise, pushing, double pushing, holding, and double holding, were measured using Doppler radar and their spectrograms investigated. A DCNN was employed to classify the spectrograms, with 90{\%} of the data utilized for training and the remaining 10{\%} for validation. After five-fold validation, the classification accuracy of the proposed method was found to be 85.6{\%}. With seven gestures, the accuracy increased to 93.1{\%}.},
author = {Kim, Youngwook and Toomajian, Brian},
doi = {10.1109/ACCESS.2016.2617282},
file = {::},
issn = {21693536},
journal = {IEEE Access},
keywords = {Deep convolutional neural networks,Doppler radar,Hand gesture,micro-Doppler signatures},
pages = {7125--7130},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Hand Gesture Recognition Using Micro-Doppler Signatures with Convolutional Neural Network}},
volume = {4},
year = {2016}
}
@inproceedings{Lien2016,
abstract = {This paper presents Soli, a new, robust, high-resolution, low-power, miniature gesture sensing technology for human-computer interaction based on millimeter-wave radar. We describe a new approach to developing a radar-based sensor optimized for human-computer interaction, building the sensor architecture from the ground up with the inclusion of radar design principles, high temporal resolution gesture tracking, a hardware abstraction layer (HAL), a solidstate radar chip and system architecture, interaction models and gesture vocabularies, and gesture recognition. We demonstrate that Soli can be used for robust gesture recognition and can track gestures with sub-millimeter accuracy, running at over 10,000 frames per second on embedded hardware.},
author = {Lien, Jaime and Gillian, Nicholas and Karagozler, M. Emre and Amihood, Patrick and Schwesig, Carsten and Olson, Erik and Raja, Hakim and Poupyrev, Ivan},
booktitle = {ACM Transactions on Graphics},
doi = {10.1145/2897824.2925953},
file = {:home/chekirou/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lien et al. - 2016 - Soli Ubiquitous gesture sensing with millimeter wave radar(2).pdf:pdf},
issn = {15577368},
keywords = {Gestures,Interaction,RF,Radar,Sensors},
month = {jul},
number = {4},
pages = {1--19},
publisher = {Association for Computing Machinery},
title = {{Soli: Ubiquitous gesture sensing with millimeter wave radar}},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925953},
volume = {35},
year = {2016}
}
@article{Zhang2017,
abstract = {Hand gesture recognition has long been a hot topic in human computer interaction. Traditional camera-based hand gesture recognition systems cannot work properly under dark circumstances. In this paper, a Doppler Radar based hand gesture recognition system using convolutional neural networks is proposed. A cost-effective Doppler radar sensor with dual receiving channels at 5.8GHz is used to acquire a big database of four standard gestures. The received hand gesture signals are then processed with time-frequency analysis. Convolutional neural networks are used to classify different gestures. Experimental results verify the effectiveness of the system with an accuracy of 98{\%}. Besides, related factors such as recognition distance and gesture scale are investigated.},
annote = {celui la est tres interesant.},
archivePrefix = {arXiv},
arxivId = {1711.02254},
author = {Zhang, Jiajun and Tao, Jinkun and Huangfu, Jiangtao and Shi, Zhiguo},
eprint = {1711.02254},
file = {:home/chekirou/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Doppler-Radar Based Hand Gesture Recognition System Using Convolutional Neural Networks(2).pdf:pdf},
journal = {Lecture Notes in Electrical Engineering},
month = {nov},
pages = {1096--1113},
publisher = {Springer Verlag},
title = {{Doppler-Radar Based Hand Gesture Recognition System Using Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1711.02254},
volume = {463},
year = {2017}
}
@inproceedings{Darrell1993,
abstract = {This paper presents a method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e. gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special-purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. We present results showing tracking and recognition of human hand gesture at over 10Hz.},
author = {Darrell, Trevor and Pentland, Alex},
booktitle = {IEEE Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.1993.341109},
isbn = {0818638826},
pages = {335--340},
publisher = {Publ by IEEE},
title = {{Space-time gestures}},
year = {1993}
}
@inproceedings{Nguyen2018,
abstract = {Touchless hand gesture using portable millimeter-wave radar sensors an enabling technology for Internet of Things (IoT) applications. In this paper, we investigate the feasibility of using a frequency modulated continuous wave (FMCW) radar with noise removal and range gating method to recognize human hand gesture for a user moving in the radar's field of view. These detected hand gestures will be applied to remote control of computers or smart TVs at a distance from 0.3 m to 1.2 m.},
author = {Nguyen, Minh Q. and Flores-Nigaglioni, Anthony and Li, Changzhi},
booktitle = {2018 IEEE MTT-S International Wireless Symposium, IWS 2018 - Proceedings},
doi = {10.1109/IEEE-IWS.2018.8400811},
isbn = {9781538663462},
keywords = {FMCW radar,IoT applications,Touchless hand gesture,noise removal method,range gating method},
month = {jun},
pages = {1--4},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Range-gating technology for millimeter-wave radar remote gesture control in IoT applications}},
year = {2018}
}
@inproceedings{Wan2014,
abstract = {In this article, we consider the design of a human gesture recognition system based on pattern recognition of signatures from a portable smart radar sensor. Powered by AAA batteries, the smart radar sensor operates in the 2.4 GHz industrial, scientific and medical (ISM) band. We analyzed the feature space using principle components and application-specific time and frequency domain features extracted from radar signals for two different sets of gestures. We illustrate that a nearest neighbor based classifier can achieve greater than 95{\%} accuracy for multi class classification using 10 fold cross validation when features are extracted based on magnitude differences and Doppler shifts as compared to features extracted through orthogonal transformations. The reported results illustrate the potential of intelligent radars integrated with a pattern recognition system for high accuracy smart home and health monitoring purposes.},
author = {Wan, Qian and Li, Yiran and Li, Changzhi and Pal, Ranadip},
booktitle = {2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2014},
doi = {10.1109/EMBC.2014.6945096},
isbn = {9781424479290},
month = {nov},
pages = {6414--6417},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Gesture recognition for smart home applications using portable radar sensors}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25571464},
volume = {2014},
year = {2014}
}
@article{Choi2019,
abstract = {Due to the development of short-range radar with high-resolution, the radar sensor has a high potential to be used in real human-computer interaction (HCI) applications. The radar sensor has advantages over optical cameras in that it is unaffected by illumination and it is able to detect the objects in an occluded environment. This paper proposes a hand gesture recognition system for a real-time application of HCI using 60 GHz frequency-modulated continuous wave (FMCW) radar, Soli, developed by Google. The overall system includes signal processing part that generates range-Doppler map (RDM) sequences without clutter and machine learning part including a long short-term memory (LSTM) encoder to learn the temporal characteristics of the RDM sequences. A set of data is collected from 10 participants for the experiment. The proposed hand gesture recognition system successfully distinguishes 10 gestures with a high classification accuracy of 99.10{\%}. It also recognizes the gestures of a new participant with an accuracy of 98.48{\%}.},
annote = {ils ont l'air d'avoir copi{\'{e}} notre papier mais avec moins de gestes  mais ils peuvrent etre utiles pour la redact
ions.},
author = {Choi, Jae Woo and Ryu, Si Jung and Kim, Jong Hwan},
doi = {10.1109/ACCESS.2019.2903586},
issn = {21693536},
journal = {IEEE Access},
keywords = {FMCW radar,LSTM encoder,gesture recognitio,machine learning,real-time interaction},
pages = {33610--33618},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Short-Range Radar Based Real-Time Hand Gesture Recognition Using LSTM Encoder}},
volume = {7},
year = {2019}
}
