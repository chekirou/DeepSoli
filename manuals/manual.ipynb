{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import utils.Dataset as u\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fonction split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1 = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\" , use= 0.001) # return a split train test of the sequences, using all the data, 50% train, 50% test\n",
    "train2, test2 = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\",frames = True, percentage = 0.8, use= 0.0001) # returns a split of the frames 80% train, 20% test, for 80% of the data\n",
    "train3, test3 = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\",frames = False, already_defined= True)# returns train test split as defined in the article\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/chekirou/Documents/SOLI/SoliData/dsp/\"\n",
    "t = transforms.Compose([u.Reshape(), u.Rescale((224,224)), u.ToTensor()]) # composition of transformations\n",
    "data = u.Data(directory,train1,transform = t) # open the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utilisation du loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_params = {'batch_size': 100, 'shuffle': True, 'num_workers': 6}\n",
    "loader = DataLoader(data,**loader_params )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_7_22', '9_0_42', '6_10_15', '6_4_4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ne pas executer , exemple type d'utilisation (avec cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#cudnn.benchmark = True # ca marche pas chez moi,peut etre qu'il faut que j'installe un truc\n",
    "\n",
    "# Parameters, num_workers c'est les threads\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 6}\n",
    "\n",
    "max_epochs = 1 # j'ai mis a 1 pour le test pour aller vite\n",
    "\n",
    "# Datasets\n",
    "train, test = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\",frames = False, percentage = 0.8, use= 0.001) # returns a split of the frames 80% train, 20% test, for 80% of the data\n",
    "\n",
    "# Generators\n",
    "directory = \"/home/chekirou/Documents/SOLI/SoliData/dsp/\"\n",
    "t = transforms.Compose([u.Reshape(), u.Rescale((224,224)), u.ToTensor()]) # composition of transformations\n",
    "training_set = u.Data(directory,train,transform = t) # open the dataset\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "\n",
    "validation_set = u.Data(directory,test,transform = t) # open the dataset\n",
    "validation_generator = DataLoader(validation_set, **params)\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        print(local_batch.size())\n",
    "        print(local_labels)\n",
    "\n",
    "        # Model computations\n",
    "        \n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
