{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import utils.Dataset as u\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fonction split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1 = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\" , use= 0.001) # return a split train test of the sequences, using all the data, 50% train, 50% test\n",
    "train2, test2 = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\",frames = True, percentage = 0.8, use= 0.0001) # returns a split of the frames 80% train, 20% test, for 80% of the data\n",
    "train3, test3 = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\",frames = False, already_defined= True)# returns train test split as defined in the article\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/chekirou/Documents/SOLI/SoliData/dsp/\"\n",
    "t = transforms.Compose([u.Reshape(), u.Rescale((224,224)), u.ToTensor()]) # composition of transformations\n",
    "data = u.Data(directory,train1,transform = t) # open the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utilisation du loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_params = {'batch_size': 100, 'shuffle': True, 'num_workers': 6}\n",
    "loader = DataLoader(data,**loader_params )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exemple type d'utilisation (avec cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [6],\n",
      "        [0],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [0],\n",
      "        [6],\n",
      "        [0],\n",
      "        [0],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [0],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [0]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [0],\n",
      "        [0]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [0],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [6],\n",
      "        [0],\n",
      "        [0],\n",
      "        [6],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [9]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [0],\n",
      "        [0],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[0],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [0],\n",
      "        [6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [9],\n",
      "        [0],\n",
      "        [6],\n",
      "        [0],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [0]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [0]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[6],\n",
      "        [6],\n",
      "        [9],\n",
      "        [0],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [0],\n",
      "        [9],\n",
      "        [6]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])\n",
      "tensor([[9],\n",
      "        [6],\n",
      "        [0],\n",
      "        [6],\n",
      "        [6],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([10, 4, 224, 224])"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dcb3dce40744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Transfer to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#cudnn.benchmark = True # ca marche pas chez moi,peut etre qu'il faut que j'installe un truc\n",
    "\n",
    "# Parameters, num_workers c'est les threads\n",
    "params = {'batch_size': 10,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "max_epochs = 1 # j'ai mis a 1 pour le test pour aller vite\n",
    "\n",
    "# Datasets\n",
    "train, test = u.split(\"/home/chekirou/Documents/SOLI/SoliData/dsp/\",frames = True, percentage = 0.8, use= 0.001) # returns a split of the frames 80% train, 20% test, for 80% of the data\n",
    "\n",
    "# Generators\n",
    "directory = \"/home/chekirou/Documents/SOLI/SoliData/dsp/\"\n",
    "t = transforms.Compose([u.Reshape(), u.Rescale((224,224)), u.ToTensor()]) # composition of transformations\n",
    "training_set = u.Data(directory,train,transform = t) # open the dataset\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "\n",
    "validation_set = u.Data(directory,test,transform = t) # open the dataset\n",
    "validation_generator = DataLoader(validation_set, **params)\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        print(local_batch.size())\n",
    "        print(local_labels)\n",
    "\n",
    "        # Model computations\n",
    "        \n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
