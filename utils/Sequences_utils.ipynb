{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import h5py\n",
    "import json\n",
    "from random import shuffle\n",
    "from Dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data sequence class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Sequences(Dataset):\n",
    "    def __init__(self, root_dir, partition, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the h5 sequences.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.partition = partition\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.partition)\n",
    "    def __getitem__(self, index):\n",
    "        sequence = self.partition[index]\n",
    "        with h5py.File(self.root_dir + '/' + sequence+ \".h5\", 'r') as f:\n",
    "            data = np.stack(tuple(f['ch{}'.format(i)] for i in range(4)), axis = -1 )\n",
    "            label = f['label'][()]\n",
    "        if self.transform != None:\n",
    "            data, label = self.transform((data, label))# make the necessary transformations\n",
    "        return data, label\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "class Reshape(object):\n",
    "    '''\n",
    "    reshape an image to 32 * 32 \n",
    "    '''\n",
    "    def __call__(self, sample):\n",
    "        data, label = sample\n",
    "        # a whole sequence \n",
    "        data = data.reshape((data.shape[0], 32,32, 4))\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        newH, newW = self.output_size\n",
    "        data, label = sample\n",
    "        data = transform.resize(data, (data.shape[0], newH, newW, data.shape[3]))\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"transposes ndarrays in sample to Tensors.\n",
    "        and transforms them to tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        data, label= sample\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        data = data.transpose((0, 3, 1, 2))\n",
    "        return torch.from_numpy(data),torch.from_numpy(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SameSize(object):\n",
    "    \" either completes a sequence with pads or subsamples it\"\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "    def __call__(self, sample):\n",
    "        data, labels = sample\n",
    "        sequences = np.zeros((self.size, *data.shape[1:]))\n",
    "        labels_2 = np.zeros((self.size, *labels.shape[1:]))\n",
    "        sequences[-data.shape[0]:] = data[:self.size]\n",
    "        labels_2[-labels.shape[0]:] = labels[:self.size]\n",
    "        return sequences, labels_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 2,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 6}\n",
    "\n",
    "max_epochs = 1 # j'ai mis a 1 pour le test pour aller vite\n",
    "directory = \"/home/chekirou/Documents/SOLI/SoliData/dsp\"\n",
    "# Datasets\n",
    "train, test = split(directory,frames = False, percentage = 0.8, use= 0.2) # returns a split of the frames 80% train, 20% test, for 80% of the data\n",
    "\n",
    "# Generators\n",
    "\n",
    "t = transforms.Compose([Reshape(), Rescale((224,224)),SameSize(40), ToTensor()]) # composition of transformations\n",
    "training_set = Data_Sequences(directory,train[:6], transform = t) # open the dataset\n",
    "training_generator = DataLoader(training_set, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, label = training_set[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def show_gesture(test, channel):\n",
    "    for i in range(test.shape[0]):\n",
    "        plt.imshow(test[i,channel])\n",
    "        plt.show()\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([40, 4, 224, 224]) torch.Size([40, 1])\n",
      "1 torch.Size([40, 4, 224, 224]) torch.Size([40, 1])\n",
      "2 torch.Size([40, 4, 224, 224]) torch.Size([40, 1])\n",
      "3 torch.Size([40, 4, 224, 224]) torch.Size([40, 1])\n",
      "4 torch.Size([40, 4, 224, 224]) torch.Size([40, 1])\n",
      "5 torch.Size([40, 4, 224, 224]) torch.Size([40, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (t, l) in enumerate(training_set):\n",
    "    print(i, t.shape, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2, 40, 4, 224, 224]) torch.Size([2, 40, 1])\n",
      "1 torch.Size([2, 40, 4, 224, 224]) torch.Size([2, 40, 1])\n",
      "2 torch.Size([2, 40, 4, 224, 224]) torch.Size([2, 40, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (test, label) in enumerate(training_generator):\n",
    "    print(i, test.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
